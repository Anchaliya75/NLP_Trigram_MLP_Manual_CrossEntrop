{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOU0m5AY1/K3YSN1sFHXHH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anchaliya75/NLP_Trigram_MLP_Manual_CrossEntrop/blob/main/Cross_Entropy_Manual_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jAKCTaaxPMg4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('data.txt','r').read().splitlines()\n"
      ],
      "metadata": {
        "id": "AjVeLXxXPX3f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xog2eFVKPaw4",
        "outputId": "1465677b-f0ee-4125-a3a4-25c2d2506edf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words[0:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rxRm927Pdjy",
        "outputId": "59b5cb0f-36f2-4b10-a3c5-4a5fd151f072"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnM9TjjRSP7K",
        "outputId": "a80b5765-9ffc-42a0-f75f-14b685bb8f44"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "IdG822PVSX39"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(words,n_gram):\n",
        "  xs= []\n",
        "  ys=[]\n",
        "  n_gram   = n_gram\n",
        "  for w  in words:\n",
        "    temp =['.']*n_gram+list(w)+['.']\n",
        "    for a  in temp[n_gram:]:\n",
        "      train_word = list(temp[:n_gram])\n",
        "      train_x_idx = [stoi[i] for i in train_word]\n",
        "      train_y_idx = stoi[a]\n",
        "      temp = temp[1:]\n",
        "      xs.append(train_x_idx)\n",
        "      ys.append(train_y_idx)\n",
        "  xs= torch.tensor(xs)\n",
        "  ys=torch.tensor(ys)\n",
        "  return xs,ys"
      ],
      "metadata": {
        "id": "ozQxElT_SjYe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually Doing Cross Entropy  loss from scratch"
      ],
      "metadata": {
        "id": "aH9kngqMSpxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "x,y = create_dataset(words[:5],3)\n",
        "X_one_hot = F.one_hot(x,num_classes =27).float()\n",
        "C  = torch.rand((27,2),generator =g)\n",
        "W1 = torch.rand((6,100),generator =g)\n",
        "b1= torch.rand(100,generator =g)\n",
        "W2 = torch.rand((100,27),generator =g)\n",
        "b2= torch.rand(27,generator  = g )\n",
        "embedding  =  (X_one_hot @ C).view(x.shape[0],-1)\n",
        "hidden = embedding @ W1  +b1\n",
        "output = hidden @ W2 +b2\n",
        "maxa  = torch.max(output)\n",
        "output -= maxa\n",
        "count = output.exp()\n",
        "probs  = count/(count.sum(axis =1 ,keepdim =True))\n",
        "loss  = -probs[torch.arange(32),y].log().mean()\n",
        "print(f\"loss of the model is  {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKgIUcRTSeQg",
        "outputId": "7bc3d72d-bd20-48f8-fd50-6dde4f3f912a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss of the model is  15.751398086547852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Entropy Loss Using Pytorch  Function"
      ],
      "metadata": {
        "id": "Mz__Q5zNSzMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "x,y = create_dataset(words[:5],3)\n",
        "X_one_hot_c = F.one_hot(x,num_classes =27).float()\n",
        "C_c  = torch.rand((27,2),generator =g)\n",
        "W1_c = torch.rand((6,100),generator =g)\n",
        "b1_c= torch.rand(100,generator =g)\n",
        "W2_c = torch.rand((100,27),generator =g)\n",
        "b2_c= torch.rand(27,generator  = g )\n",
        "embedding_c  =  (X_one_hot @ C).view(x.shape[0],-1)\n",
        "hidden_c = embedding @ W1  +b1\n",
        "output_c = hidden @ W2 +b2\n",
        "loss_c  =  F.cross_entropy(output,y)\n",
        "print(f\"loss of the model is  {loss_c}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2TQBv2ES4kw",
        "outputId": "8d247a16-fd28-4e85-bce7-27283bf0282d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss of the model is  15.751397132873535\n"
          ]
        }
      ]
    }
  ]
}